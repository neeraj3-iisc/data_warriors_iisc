{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba88574",
   "metadata": {},
   "source": [
    "# EV Adoption Modeling (Improved Spark Pipeline)\n",
    "\n",
    "This notebook is an improved PySpark pipeline for predicting `ev_adoption_probability`\n",
    "using **Spark-supported models only**.\n",
    "\n",
    "It adds:\n",
    "\n",
    "- Rich **feature engineering** (interaction + polynomial features)\n",
    "- Proper **train/test split before target encoding**\n",
    "- **Target encoding** for high-cardinality `city` and `state`\n",
    "- A tuned **Gradient Boosted Trees (GBT)** model using `CrossValidator`\n",
    "- Comparison with a tuned **Random Forest**\n",
    "- Option to toggle **raw vs log-transformed label**\n",
    "\n",
    "> Note: The exact R² you reach (e.g., 0.85–0.90) depends on the signal in your data.\n",
    "This notebook is structured to *maximize* performance with Spark's built-in models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f832033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 0. Imports & Spark Session\n",
    "# ==============================\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import (\n",
    "    RandomForestRegressor,\n",
    "    GBTRegressor,\n",
    "    LinearRegression,\n",
    "    DecisionTreeRegressor,\n",
    "    GeneralizedLinearRegression\n",
    ")\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "print(\"Using PySpark - EV adoption modeling\")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "      .appName(\"EVAdoptionImproved\")\n",
    "      .master(\"yarn\")                     # adjust for your cluster if needed\n",
    "      .config(\"spark.submit.deployMode\", \"client\")\n",
    "      .config(\"spark.executor.instances\", \"2\")\n",
    "      .config(\"spark.executor.cores\", \"2\")\n",
    "      .config(\"spark.executor.memory\", \"1536m\")\n",
    "      .config(\"spark.executor.memoryOverhead\", \"512m\")\n",
    "      .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "      .config(\"spark.default.parallelism\", \"4\")\n",
    "      .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "      .config(\"spark.hadoop.dfs.client.use.datanode.hostname\", \"true\")\n",
    "      .getOrCreate()\n",
    ")\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97820e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1. Load Dataset\n",
    "# ==============================\n",
    "\n",
    "data_path = \"hdfs://namenode:9000/hadoop/ev_dataset_final.csv\"  # <-- change if needed\n",
    "\n",
    "df = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(data_path)\n",
    ")\n",
    "\n",
    "print(f\"Loaded {df.count():,} rows, {len(df.columns)} columns\")\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f255d-37aa-44c3-be66-57012f23911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_ROWS = 50000\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows > TARGET_ROWS:\n",
    "    frac = TARGET_ROWS / float(total_rows)\n",
    "    df_sampled = df.sample(withReplacement=False, fraction=frac, seed=42)\n",
    "    # Safety: if sample is slightly off, enforce limit\n",
    "    df_sampled = df_sampled.limit(TARGET_ROWS)\n",
    "    print(f\"Using sampled dataset: {df_sampled.count()} rows (target {TARGET_ROWS})\")\n",
    "else:\n",
    "    df_sampled = df\n",
    "    print(f\"Dataset has only {total_rows} rows, using full data\")\n",
    "\n",
    "# then use df_sampled instead of df\n",
    "df = df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f77014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 2. Missing Value Handling\n",
    "# ==============================\n",
    "\n",
    "total_rows = df.count()\n",
    "print(\"Total rows:\", total_rows)\n",
    "\n",
    "numeric_cols = []\n",
    "categorical_cols = []\n",
    "\n",
    "for col_name in df.columns:\n",
    "    dtype = str(df.schema[col_name].dataType)\n",
    "    if 'double' in dtype.lower() or 'int' in dtype.lower():\n",
    "        numeric_cols.append(col_name)\n",
    "    elif 'string' in dtype.lower() and col_name not in ['city', 'date', 'state']:\n",
    "        categorical_cols.append(col_name)\n",
    "\n",
    "print(f\"Numeric columns: {len(numeric_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "print(\"Identity columns treated separately: city, date, state\")\n",
    "\n",
    "# Fill numeric nulls with median\n",
    "df_filled = df\n",
    "for col_name in numeric_cols:\n",
    "    median_val = df_filled.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    df_filled = df_filled.fillna({col_name: median_val})\n",
    "\n",
    "# Fill categorical nulls with mode\n",
    "for col_name in categorical_cols:\n",
    "    mode_row = df_filled.groupBy(col_name).count().orderBy(F.desc(\"count\")).first()\n",
    "    if mode_row and mode_row[0] is not None:\n",
    "        mode_val = mode_row[0]\n",
    "        df_filled = df_filled.fillna({col_name: mode_val})\n",
    "\n",
    "# Check remaining nulls\n",
    "total_nulls = 0\n",
    "for col_name in df_filled.columns:\n",
    "    null_count = df_filled.filter(F.col(col_name).isNull()).count()\n",
    "    total_nulls += null_count\n",
    "    if null_count > 0:\n",
    "        print(f\"{col_name}: {null_count} nulls\")\n",
    "\n",
    "print(\"Total remaining nulls:\", total_nulls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 3. Base Feature Engineering + Label\n",
    "# ==============================\n",
    "\n",
    "# Convert date to year/month\n",
    "df_model = df_filled.withColumn(\n",
    "    \"date_parsed\",\n",
    "    F.to_date(F.col(\"date\"), \"dd/MM/yy\")\n",
    ")\n",
    "\n",
    "df_model = (\n",
    "    df_model\n",
    "      .withColumn(\"year\", F.year(\"date_parsed\"))\n",
    "      .withColumn(\"month\", F.month(\"date_parsed\"))\n",
    "      .drop(\"date\", \"date_parsed\")\n",
    ")\n",
    "\n",
    "# Core engineered features\n",
    "df_model = df_model.withColumn(\n",
    "    \"affordability_index\", F.col(\"vehicle_price_ev\") / F.col(\"income_level\")\n",
    ")\n",
    "\n",
    "df_model = df_model.withColumn(\n",
    "    \"infra_confidence_score\", F.col(\"battery_range_km\") * F.col(\"charging_stations_per_10km\")\n",
    ")\n",
    "\n",
    "df_model = df_model.withColumn(\n",
    "    \"savings_ratio\", F.col(\"fuel_price_per_litre\") / F.col(\"electricity_cost_per_kwh\")\n",
    ")\n",
    "\n",
    "df_model = df_model.withColumn(\n",
    "    \"resale_confidence\",\n",
    "    F.when(F.col(\"vehicle_resale_value_ice\") == 0, 0)\n",
    "     .otherwise(F.col(\"vehicle_resale_value_ev\") / F.col(\"vehicle_resale_value_ice\"))\n",
    ")\n",
    "\n",
    "df_model = df_model.withColumn(\n",
    "    \"market_momentum\",\n",
    "    F.when(F.col(\"ice_sales_last_year\") == 0, 0)\n",
    "     .otherwise(F.col(\"ev_sales_last_year\") / F.col(\"ice_sales_last_year\"))\n",
    ")\n",
    "\n",
    "# Toggle: use raw probability or log-transformed label\n",
    "use_log_label = False  # set True to try log(label)\n",
    "\n",
    "if use_log_label:\n",
    "    df_model = df_model.withColumn(\n",
    "        \"log_ev_adoption\", F.log(F.col(\"ev_adoption_probability\") + F.lit(1e-6))\n",
    "    )\n",
    "    label_col = \"log_ev_adoption\"\n",
    "else:\n",
    "    label_col = \"ev_adoption_probability\"\n",
    "\n",
    "# Drop rows with null label (just in case)\n",
    "df_model = df_model.filter(F.col(label_col).isNotNull())\n",
    "\n",
    "print(\"df_model schema:\")\n",
    "df_model.printSchema()\n",
    "df_model.select(\"city\", \"state\", label_col, \"affordability_index\", \"infra_confidence_score\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 4. High-Impact Interaction & Polynomial Features\n",
    "# ==============================\n",
    "\n",
    "# Infrastructure interactions\n",
    "df_model = df_model.withColumn(\"range_x_stations\", \n",
    "    F.col(\"battery_range_km\") * F.col(\"charging_stations_per_10km\"))\n",
    "\n",
    "df_model = df_model.withColumn(\"infra_growth_x_range\", \n",
    "    F.col(\"charging_infra_growth_rate\") * F.col(\"battery_range_km\"))\n",
    "\n",
    "df_model = df_model.withColumn(\"gov_infra_x_stations\",\n",
    "    F.col(\"gov_infra_investment_crores\") * F.col(\"charging_stations_per_10km\"))\n",
    "\n",
    "# Economic interactions\n",
    "df_model = df_model.withColumn(\"income_x_subsidy\", \n",
    "    F.col(\"income_level\") * F.col(\"ev_subsidy_amount\"))\n",
    "\n",
    "df_model = df_model.withColumn(\"affordability_x_subsidy\", \n",
    "    F.col(\"affordability_index\") * F.col(\"ev_subsidy_amount\"))\n",
    "\n",
    "df_model = df_model.withColumn(\"ev_price_x_income\",\n",
    "    F.col(\"vehicle_price_ev\") * F.col(\"income_level\"))\n",
    "\n",
    "# Environment & traffic interactions\n",
    "df_model = df_model.withColumn(\"aqi_x_population\", \n",
    "    F.col(\"avg_city_aqi\") * F.col(\"population_density\"))\n",
    "\n",
    "df_model = df_model.withColumn(\"congestion_x_population\", \n",
    "    F.col(\"traffic_congestion_index\") * F.col(\"population_density\"))\n",
    "\n",
    "df_model = df_model.withColumn(\"aqi_x_congestion\", \n",
    "    F.col(\"avg_city_aqi\") * F.col(\"traffic_congestion_index\"))\n",
    "\n",
    "# Behavioral interactions\n",
    "df_model = df_model.withColumn(\"awareness_x_anxiety\", \n",
    "    F.col(\"ev_awareness_score\") * F.col(\"consumer_range_anxiety_score\"))\n",
    "\n",
    "df_model = df_model.withColumn(\"momentum_x_awareness\",\n",
    "    F.col(\"market_momentum\") * F.col(\"ev_awareness_score\"))\n",
    "\n",
    "df_model = df_model.withColumn(\"resale_x_awareness\",\n",
    "    F.col(\"resale_confidence\") * F.col(\"ev_awareness_score\"))\n",
    "\n",
    "# Polynomial features (degree 2)\n",
    "df_model = df_model.withColumn(\"range_sq\", F.col(\"battery_range_km\")**2)\n",
    "df_model = df_model.withColumn(\"aqi_sq\", F.col(\"avg_city_aqi\")**2)\n",
    "df_model = df_model.withColumn(\"population_sq\", F.col(\"population_density\")**2)\n",
    "df_model = df_model.withColumn(\"congestion_sq\", F.col(\"traffic_congestion_index\")**2)\n",
    "\n",
    "print(\"Sample of engineered columns:\")\n",
    "df_model.select(\n",
    "    \"battery_range_km\", \"charging_stations_per_10km\",\n",
    "    \"range_x_stations\", \"infra_growth_x_range\",\n",
    "    \"income_x_subsidy\", \"aqi_x_population\",\n",
    "    \"awareness_x_anxiety\"\n",
    ").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eafc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 5. Train/Test Split + Target Encoding\n",
    "# ==============================\n",
    "\n",
    "train_df, test_df = df_model.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Train rows: {train_df.count():,}\")\n",
    "print(f\"Test rows: {test_df.count():,}\")\n",
    "\n",
    "# Target encoding on TRAIN only\n",
    "city_avg = train_df.groupBy(\"city\").agg(F.avg(label_col).alias(\"city_encoded\"))\n",
    "state_avg = train_df.groupBy(\"state\").agg(F.avg(label_col).alias(\"state_encoded\"))\n",
    "global_avg = train_df.select(F.avg(label_col)).first()[0]\n",
    "print(\"Global mean label:\", global_avg)\n",
    "\n",
    "def apply_target_encoding(data, city_map, state_map, global_mean):\n",
    "    enc = (\n",
    "        data\n",
    "        .join(city_map, on=\"city\", how=\"left\")\n",
    "        .join(state_map, on=\"state\", how=\"left\")\n",
    "    )\n",
    "    enc = enc.na.fill({\n",
    "        \"city_encoded\": global_mean,\n",
    "        \"state_encoded\": global_mean\n",
    "    })\n",
    "    return enc\n",
    "\n",
    "train_ready = apply_target_encoding(train_df, city_avg, state_avg, global_avg)\n",
    "test_ready  = apply_target_encoding(test_df, city_avg, state_avg, global_avg)\n",
    "\n",
    "train_ready.select(\"city\", \"state\", \"city_encoded\", \"state_encoded\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb212a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 6. Assembler + Baseline\n",
    "# ==============================\n",
    "\n",
    "final_feature_cols = [\n",
    "    # Core engineered\n",
    "    \"affordability_index\",\n",
    "    \"infra_confidence_score\",\n",
    "    \"savings_ratio\",\n",
    "    \"city_encoded\",\n",
    "    \"state_encoded\",\n",
    "    \"resale_confidence\",\n",
    "    \"market_momentum\",\n",
    "\n",
    "    # Original important\n",
    "    \"fuel_price_per_litre\",\n",
    "    \"avg_city_aqi\",\n",
    "    \"vehicle_price_ev\",\n",
    "    \"income_level\",\n",
    "    \"charging_stations_per_10km\",\n",
    "    \"ev_subsidy_amount\",\n",
    "    \"maintenance_cost_ev\",\n",
    "    \"charging_time_minutes\",\n",
    "    \"population_density\",\n",
    "    \"public_transport_score\",\n",
    "    \"traffic_congestion_index\",\n",
    "    \"ev_awareness_score\",\n",
    "    \"gov_infra_investment_crores\",\n",
    "    \"charging_infra_growth_rate\",\n",
    "    \"consumer_range_anxiety_score\",\n",
    "    \"battery_range_km\",\n",
    "\n",
    "    # Interaction features\n",
    "    \"range_x_stations\",\n",
    "    \"infra_growth_x_range\",\n",
    "    \"gov_infra_x_stations\",\n",
    "    \"income_x_subsidy\",\n",
    "    \"affordability_x_subsidy\",\n",
    "    \"ev_price_x_income\",\n",
    "    \"aqi_x_population\",\n",
    "    \"congestion_x_population\",\n",
    "    \"aqi_x_congestion\",\n",
    "    \"awareness_x_anxiety\",\n",
    "    \"momentum_x_awareness\",\n",
    "    \"resale_x_awareness\",\n",
    "\n",
    "    # Polynomial features\n",
    "    \"range_sq\",\n",
    "    \"aqi_sq\",\n",
    "    \"population_sq\",\n",
    "    \"congestion_sq\",\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=final_feature_cols, outputCol=\"features\")\n",
    "\n",
    "train_data = assembler.transform(train_ready).select(\"features\", label_col)\n",
    "test_data  = assembler.transform(test_ready).select(\"features\", label_col)\n",
    "\n",
    "print(\"Assembled training sample:\")\n",
    "train_data.show(3, truncate=False)\n",
    "\n",
    "# Baseline model: always predict mean\n",
    "train_mean = train_data.select(F.avg(label_col)).first()[0]\n",
    "baseline = test_data.withColumn(\"prediction\", F.lit(train_mean))\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "baseline_r2 = evaluator_r2.evaluate(baseline)\n",
    "baseline_rmse = evaluator_rmse.evaluate(baseline)\n",
    "baseline_mae = evaluator_mae.evaluate(baseline)\n",
    "\n",
    "print(f\"Baseline (mean-only) -> R²: {baseline_r2:.4f}, RMSE: {baseline_rmse:.4f}, MAE: {baseline_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 7. Tuned Gradient Boosted Trees (GBT) via CrossValidator\n",
    "# ==============================\n",
    "\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=label_col, seed=42)\n",
    "\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "      .addGrid(gbt.maxDepth, [5, 7, 9])\n",
    "      .addGrid(gbt.maxIter, [150, 250, 300])\n",
    "      .addGrid(gbt.stepSize, [0.05, 0.1, 0.15])\n",
    "      .addGrid(gbt.maxBins, [64, 128, 256])\n",
    "      .addGrid(gbt.subsamplingRate, [0.8, 1.0])\n",
    "      .build()\n",
    ")\n",
    "\n",
    "evaluator_cv = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=gbt,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_cv,\n",
    "    numFolds=3,\n",
    "    parallelism=4  # adjust based on cluster\n",
    ")\n",
    "\n",
    "print(\"Training tuned GBT (this may take a while)...\")\n",
    "cv_model = cv.fit(train_data)\n",
    "gbt_preds = cv_model.transform(test_data)\n",
    "\n",
    "gbt_r2 = evaluator_r2.evaluate(gbt_preds)\n",
    "gbt_rmse = evaluator_rmse.evaluate(gbt_preds)\n",
    "gbt_mae = evaluator_mae.evaluate(gbt_preds)\n",
    "\n",
    "print(f\"Tuned GBT -> R²: {gbt_r2:.4f}, RMSE: {gbt_rmse:.4f}, MAE: {gbt_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b99b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 8. Tuned Random Forest (Optional Comparison)\n",
    "# ==============================\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=label_col, seed=42)\n",
    "\n",
    "rf_paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "      .addGrid(rf.numTrees, [100, 200])      # 2\n",
    "      .addGrid(rf.maxDepth, [8, 12])        # 2\n",
    "      .addGrid(rf.subsamplingRate, [0.8])   # 1\n",
    "      .build()\n",
    ")\n",
    "\n",
    "evaluator_cv = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rf_cv = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=rf_paramGrid,\n",
    "    evaluator=evaluator_cv,\n",
    "    numFolds=2,          # 2 folds instead of 3\n",
    "    parallelism=4\n",
    ")\n",
    "\n",
    "print(\"Training small-grid tuned Random Forest...\")\n",
    "rf_cv_model = rf_cv.fit(train_data)\n",
    "rf_preds = rf_cv_model.transform(test_data)\n",
    "\n",
    "rf_r2 = evaluator_r2.evaluate(rf_preds)\n",
    "rf_rmse = evaluator_rmse.evaluate(rf_preds)\n",
    "rf_mae = evaluator_mae.evaluate(rf_preds)\n",
    "\n",
    "print(f\"Tuned RF (small grid) -> R²: {rf_r2:.4f}, RMSE: {rf_rmse:.4f}, MAE: {rf_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d681ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 9. Summary of Results\n",
    "# ==============================\n",
    "\n",
    "print(\"\\n=== Final Model Comparison ===\")\n",
    "print(f\"Baseline (mean-only)  : R² = {baseline_r2:.4f}, RMSE = {baseline_rmse:.4f}, MAE = {baseline_mae:.4f}\")\n",
    "print(f\"Tuned GBT             : R² = {gbt_r2:.4f}, RMSE = {gbt_rmse:.4f}, MAE = {gbt_mae:.4f}\")\n",
    "print(f\"Tuned Random Forest   : R² = {rf_r2:.4f}, RMSE = {rf_rmse:.4f}, MAE = {rf_mae:.4f}\")\n",
    "\n",
    "print(\"\\nTips if R² is below your target:\")\n",
    "print(\"  - Change use_log_label between True/False and re-run the notebook.\")\n",
    "print(\"  - Inspect RF feature importances and drop very weak/noisy features.\")\n",
    "print(\"  - Adjust hyperparameter grids slightly around best values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aeee87-d273-49f1-b97e-7034ad1edb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()\n",
    "print(\"Spark session stopped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d6e16-1b4a-4a3c-845e-f8e7b6236aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
